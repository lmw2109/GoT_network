{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation - Game of Thrones - Extracting Relationships\n",
    "\n",
    "**Quick Notes**\n",
    "\n",
    "This Notebook loops through all scripts to extract relationships between the specified characters.\n",
    "\n",
    "The relationship extracts represent a 'source' - 'target' edge list and are saved as '.csv' file for visualization!\n",
    "\n",
    "**Sources**\n",
    "\n",
    "- [Pandas Documentation](https://pandas.pydata.org/docs/)\n",
    "\n",
    "- [Numpy Documentation](https://numpy.org/doc/)\n",
    "\n",
    "- [Python os](https://docs.python.org/3/library/os.html)\n",
    "\n",
    "- [Python re](https://docs.python.org/3/library/re.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Scripts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All season directories\n",
    "all_seasons = [s for s in os.scandir('Data') if 'Season' in s.name]\n",
    "\n",
    "# Sort directories\n",
    "all_seasons.sort(key=lambda x: x.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All episode scripts\n",
    "season_episodes = []\n",
    "for s in range(0, len(all_seasons)):\n",
    "    episodes = [e for e in os.scandir(all_seasons[s]) if '.txt' in e.name]\n",
    "    season_episodes.append(episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to get a season:\n",
    "test_season = season_episodes[0]\n",
    "# How to get an episode of a season:\n",
    "test_episode = season_episodes[0][0]\n",
    "# Episodes are not ordered (We are only interested in Season ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in character csv\n",
    "character_df = pd.read_csv(\"characters.csv\", header=0, index_col=0)\n",
    "# Identiteis\n",
    "identities = character_df['Character']\n",
    "# Firstnames\n",
    "firstnames = character_df['Character_firstname']\n",
    "# Nicknames\n",
    "nicknames = character_df['Character_nickname']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all characters that we want to scan for (first & nicknames)\n",
    "# characters are going to be mapped to Identities later on to avoid duplication\n",
    "characters = []\n",
    "\n",
    "def get_filter_chars(characters, names):\n",
    "    for element in names:\n",
    "        cur = str(element)\n",
    "        if cur != 'nan':\n",
    "            characters.append(cur)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_filter_chars(characters, nicknames)\n",
    "get_filter_chars(characters, firstnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n"
     ]
    }
   ],
   "source": [
    "# 162 chars + 4 nicknames\n",
    "print(len(characters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Process scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_episode(episode):\n",
    "    script = open(episode).readlines()\n",
    "    script_df = pd.DataFrame(script)\n",
    "    return script_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to store appearances in a dictionary\n",
    "def appearances(episode_df, characters):\n",
    "    # create defaultdict\n",
    "    char_dict = defaultdict(list)\n",
    "    # get characters\n",
    "    for name in characters:\n",
    "        get_lines(episode_df, name, char_dict)\n",
    "    # return defaultdict\n",
    "    return char_dict\n",
    "\n",
    "# Helper function to get lines of appearances\n",
    "def get_lines(episode_df, name, dict):\n",
    "    counter = 0\n",
    "    for i in range(episode_df.index[-1]):\n",
    "        cur = episode_df.iloc[i][0]\n",
    "        search = re.search(name, cur)\n",
    "        counter += 1\n",
    "\n",
    "        # Appends characters to a dict\n",
    "        if search is not None:\n",
    "            dict[counter].append(str(search.group(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads dict into dataframe for further use\n",
    "def load_dict(dict):\n",
    "    # dataframe\n",
    "    frame = pd.DataFrame.from_dict(dict, orient='index')\n",
    "    # sort by index (which represents line)\n",
    "    frame.sort_index(inplace=True)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to process scripts\n",
    "test_df = load_episode(test_episode)\n",
    "test_dict = appearances(test_df, characters)\n",
    "t_dict_df = load_dict(test_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Extract Relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function help identify characters\n",
    "def find_indentity(name):\n",
    "    # Check if name is a nickname & return identity if so\n",
    "    x = character_df[character_df['Character_nickname']==name].values\n",
    "    if x.size > 0:\n",
    "        return x[0][0]\n",
    "    # Check if name is a firstname & return identity if so   \n",
    "    y = character_df[character_df['Character_firstname']==name].values\n",
    "    if y.size > 0:\n",
    "        return y[0][0]\n",
    "    # Else return name\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_crawler(dict_df):\n",
    "    # Create relationships\n",
    "    relationships = []\n",
    "\n",
    "    # For the appearances dict dataframe\n",
    "    for i in range(dict_df.index[-1]):\n",
    "        end_i = min(i+3, dict_df.index[-1])\n",
    "        cur_window = dict_df.iloc[i:end_i].values.tolist()\n",
    "\n",
    "        char_list = []\n",
    "        # Append identities of current window to dict_df (nested for loops are ugly...)\n",
    "        for row in cur_window:\n",
    "            for name in row:\n",
    "                if name:\n",
    "                    identity = find_indentity(name)\n",
    "                    char_list.append(identity)\n",
    "\n",
    "        # Remove duplicated chars next to each other\n",
    "        char_unique = [char_list[i] for i in range(len(char_list))\n",
    "                        if (i==0) or char_list[i] != char_list[i-1]]\n",
    "\n",
    "        # Append to relationships\n",
    "        if len(char_unique) > 1:\n",
    "            for idx, a in enumerate(char_unique[:-1]):\n",
    "                b = char_unique[idx + 1]\n",
    "                relationships.append({\"source\": a, \"target\": b})\n",
    "    # create dataframe\n",
    "    relationships_df = pd.DataFrame(relationships)\n",
    "    # sort dataframe\n",
    "    relationships_df = pd.DataFrame(np.sort(relationships_df.values, axis = 1), columns = relationships_df.columns)\n",
    "    # retrun sorted datagrame\n",
    "    return relationships_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to extract relations\n",
    "t_relations_df = window_crawler(t_dict_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Create Weighted Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_edge(relationships_df):\n",
    "    # Add a value to each instance\n",
    "    relationships_df[\"value\"] = 1\n",
    "    # Aggragate values\n",
    "    relationships_df = relationships_df.groupby([\"source\",\"target\"], sort=False, as_index=False).sum()\n",
    "    return relationships_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to create weighted edges\n",
    "weighted_edges = weighted_edge(t_relations_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - Join Multiple Weighted Edge Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to concat all weighted edges from a collection of dataframes\n",
    "def concat_dataframes(dataframes):\n",
    "    b = len(dataframes) -1\n",
    "    season_relations = dataframes[0]\n",
    "    for i in range(0, b):\n",
    "        season_relations = pd.concat([season_relations, dataframes[i+1]])\n",
    "    sort_season_relations = season_relations.groupby([\"source\",\"target\"], sort=False, as_index=False).sum()\n",
    "    return sort_season_relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Application & Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 - Loop through all seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with first season\n",
    "counter = 1\n",
    "\n",
    "for season in season_episodes:\n",
    "    # open a dataframe\n",
    "    dataframes = []\n",
    "    for episode in season:\n",
    "        # 2 - Process the episode and return appearances dataframe\n",
    "        script = load_episode(episode)\n",
    "        ap_dict = appearances(script, characters)\n",
    "        ap_dict_df = load_dict(ap_dict)\n",
    "        # 3 - Extract Relationships\n",
    "        rel_df = window_crawler(ap_dict_df)\n",
    "        source_target_weight = weighted_edge(rel_df)\n",
    "        # Append frames\n",
    "        dataframes.append(source_target_weight)\n",
    "    # concat all dataframes\n",
    "    cur_season = concat_dataframes(dataframes)\n",
    "    # name and save csv\n",
    "    name = 'Season_'+str(counter)+'_rel_df.csv'\n",
    "    cur_season.to_csv(name)\n",
    "    # Increment\n",
    "    counter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
